# ğŸ’¬ DialoGPT Large: Dialogue Evaluation & Visualization

This project demonstrates how to evaluate and visualize the performance of Microsoft's `DialoGPT-large` conversational language model using a dataset sourced from Kaggle.

---

## ğŸ“‚ Dataset

- **Source**: [DialoGPT Dataset (KaggleHub)](https://www.kaggle.com/datasets/mathurinache/dialogptlarge)
- **Model Used**: microsoft/DialoGPT-large
- **Usage**: Token-level evaluation and response generation

---

## ğŸ› ï¸ Tools & Libraries

- Python 3  
- Hugging Face Transformers  
- PyTorch  
- KaggleHub  
- Matplotlib, Seaborn  
- WordCloud *(optional)*

---

## ğŸ“Œ Features

- ğŸ”„ Dataset download using KaggleHub  
- ğŸ§½ Preprocessing and cleaning of dialogue data  
- ğŸ§  Tokenization using Hugging Face `transformers`  
- ğŸ“Š Perplexity calculation for evaluating model performance  
- ğŸ“ˆ Visual tools:
  - Loss graph over time
  - Token confidence visualization
  - Optional word cloud generation

---

## âš™ï¸ Methodology

1. **Setup**
   - Upload `kaggle.json` to authenticate KaggleHub
   - Download dataset from Kaggle using `kagglehub`

2. **Model & Tokenizer**
   - Load `microsoft/DialoGPT-large` from Hugging Face
   - Process text using the tokenizer

3. **Evaluation**
   - Compute perplexity over the test samples
   - Visualize training loss trends
   - Visualize token-level confidence scores

---

## ğŸ§ª Usage

### ğŸ“¦ Install Dependencies (Colab or Jupyter)

```python
!pip install kagglehub transformers torch wordcloud matplotlib seaborn
ğŸ“ Upload Dataset Key
python
Copy
Edit
from google.colab import files
files.upload()  # Upload your kaggle.json
â¬‡ï¸ Download Dataset
python
Copy
Edit
import kagglehub
path = kagglehub.dataset_download("mathurinache/dialogptlarge")
ğŸ§¼ Preprocess & Tokenize
python
Copy
Edit
cleaned = clean_text(raw_text)
tokens = tokenize_dialogues([cleaned])
ğŸ“‰ Evaluate Perplexity
python
Copy
Edit
ppl = calculate_perplexity(tokens)
print("Model Perplexity:", ppl)
ğŸ“Š Visualize Loss and Confidence
python
Copy
Edit
plot_loss_graph([1.85, 1.72, 1.55, 1.42])
visualize_token_confidence("How are you doing today?")
ğŸ“ Project Structure
perl
Copy
Edit
ğŸ“¦ dialoGPT-dialogue-eval
â”œâ”€â”€ dialoGPT_dialogue_eval.py       # Full source code
â”œâ”€â”€ sample_dataset/                 # (Optional) Dialogue examples
â”œâ”€â”€ README.md                       # Project documentation
â”œâ”€â”€ requirements.txt                # Dependencies list
ğŸ“‰ Visualizations
Token-level confidence scores using softmax logits

Training loss vs. epoch

(Optional) Word cloud from dialogues

ğŸš€ Future Enhancements
Integrate user-controlled conversation loops

Fine-tune DialoGPT with domain-specific data

Build interactive chatbot interface

Deploy with Streamlit or Gradio for live demos

ğŸ‘¨â€ğŸ’» Author
Deekshith Poleboina
ğŸ“ GitHub: https://github.com/Deekshithpoleboina

ğŸ“„ License
This project is licensed under the MIT License. See the LICENSE file for details.
